{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5531b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -== ARQUIVO COM FUNCOES CRIADAS PARA A LEITURA MANIPULACAO DE DADOS ====================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b18a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================= IMPORTANDO PACOTES================================================================== \n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time as t\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "import datetime as dt\n",
    "\n",
    "from osgeo import osr\n",
    "from osgeo import gdal\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eddb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================= FUNCAO RETORNA LISTA DE ARQUIVOS -=======================\n",
    "\n",
    "def retorna_lista(caminho_do_arquivo):\n",
    "    lista = []\n",
    "    for nome_arquivo in os.listdir(caminho_do_arquivo):\n",
    "        aux = os.path.join(caminho_do_arquivo, nome_arquivo)\n",
    "        lista.append(aux)\n",
    "    lista = sorted(lista)\n",
    "    return lista \n",
    "#------------------------------------------------------------------\n",
    "# -- DESCRICAO ---\n",
    "#  chamando a funcao enviando caminho do diretorio e a funcao retorna um array com a lista ordenada dos arquivos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83ab443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================ Funcao separa por altura do csv do INPE ========================================\n",
    "#\n",
    "# CRIANDO FUNÇÃO PARA SERPARAR POR PRESSAO  versao 1.0\n",
    "# def separando_dados_altura(arquivo, pressao1, pressao2):\n",
    "#     arquivo = pd.DataFrame(arquivo)\n",
    "#     arquivo = arquivo.astype(float)\n",
    "    \n",
    "#     #aux = arquivo[np.logical_or(arquivo['press'] > int(altura1) , arquivo['press'] < int(altura2) )]\n",
    "#     aux =  arquivo.loc[ arquivo['press'] <= int(pressao2)]\n",
    "#     aux = aux.loc[arquivo['press'] >= int(pressao1)]\n",
    "#     return aux\n",
    "\n",
    "# =============== VERSAO ATUALIZADA 19-09-23 =============================================================\n",
    "def separando_dados_altura(arquivo, valor1, valor2, VAR):\n",
    "    arquivo = pd.DataFrame(arquivo)\n",
    "    arquivo = arquivo.astype(float)\n",
    "        \n",
    "#     aux =  arquivo.loc[ arquivo[VAR] <= int(valor2)]\n",
    "#     aux = aux.loc[aux[VAR] >= int(valor1)]\n",
    "    \n",
    "    aux = arquivo.loc[(arquivo[VAR] >= float(valor1)) &\n",
    "                      (arquivo[VAR] <= float(valor2))\n",
    "                     ]\n",
    "\n",
    "    return aux\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "# -- DESCRICAO ---\n",
    "#  chame a funcao  enviando um data frame e ele retorna a coluna  somente os dados com a pressao desejada \n",
    "#  Tem que manipular corretamente \n",
    "\n",
    "#==============================FUNCIONA EXCLUSIVAMENTE PARA OS ARQUIVOS DE CSV INPE==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5bd33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================ Funcao SEPARA DETERMINADA LAT LON ========================================\n",
    "## QUERO DETERMINADA  LAT E LON\n",
    "def grade_lat_lon(arquivo, lat_sup, lat_inf, lon_esq,lon_dir):  \n",
    "    arquivo = pd.DataFrame(arquivo)\n",
    "    arquivo = arquivo.astype(float)\n",
    "    aux = arquivo.loc[(arquivo['lat'] <= float(lat_sup)) & \n",
    "                  (arquivo['lat'] >= float(lat_inf)) & \n",
    "                  (arquivo['lon'] >= float(lon_esq)) &\n",
    "                  (arquivo['lon'] <= float(lon_dir))\n",
    "                     ] \n",
    "    return aux\n",
    "#==================================================================================================================\n",
    "# ========= EXPLICAÇÕES ============\n",
    "# FUNCAO PARA PEGAR DETERMINADA LAT E LON NO ARQUIVO CSV INPE \n",
    "# ONDE  LAT_SUP É A LAT MAIS PROXIMA AO EIXO DO EQUADOR\n",
    "# LAT_IN É A MAIS PROXIMA DO ARTICO\n",
    "# LONG_ESQ É A LAT DE MAIOR VALOR NEGATIVO\n",
    "#LONG_DIR É A DE MENOR VALOR , MAIS PROXIMO AO MERIDIANO DE GREENWICH\n",
    "#==================================================================================================================\n",
    "#==============================FUNCIONA EXCLUSIVAMENTE PARA OS ARQUIVOS DE CSV INPE==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c95018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================FUNÇAO QUE CALCULA O VENTO ========================== \n",
    "# ====================================================== =================== =====\n",
    "\n",
    "def calcula_vento(arquivo):\n",
    "    arquivo = pd.DataFrame(arquivo)\n",
    "                         \n",
    "    arquivo = arquivo.astype(float)\n",
    "       \n",
    "    lon = (arquivo['lon'])\n",
    "    lat = (arquivo['lat'])\n",
    "    m = (arquivo['spd'])\n",
    "    u = m * np.sin((360 - arquivo['dir']) * np.pi/180)\n",
    "    v = -m * np.cos((360- arquivo['dir']) * np.pi/180)\n",
    "    u_norm = u / np.sqrt(u ** 2.0 + v ** 2.0)\n",
    "    v_norm = v / np.sqrt(u ** 2.0 + v ** 2.0)\n",
    "    \n",
    "    return lon, lat, u_norm, v_norm\n",
    "# ================================================================================================================\n",
    "# EXEMPLO DE COMO O DADO DEVERIA ABRIR SEM PRECISAR CHAMAR A FUNÇÃO \n",
    "# lon = (dados_inpe_100_200['lon'])\n",
    "# lat = (dados_inpe_100_200['lat'])\n",
    "# m = dados_inpe_100_200['spd']\n",
    "\n",
    "# u = m * np.sin((360 - dados_inpe_100_200['dir']) * np.pi/180)\n",
    "# v = -m * np.cos((360- dados_inpe_100_200['dir']) * np.pi/180) \n",
    "\n",
    "# u_norm = u / np.sqrt(u ** 2.0 + v ** 2.0)\n",
    "# v_norm = v / np.sqrt(u ** 2.0 + v ** 2.0)\n",
    "# ================================================================================================================\n",
    "# #============= OBS\n",
    "# Não consegui resolver o problema para enviar qlqr arquivo \n",
    "# long,lati, u_norm, v_norm = fpl.calcula_vento(dados_inpe_100_200,'lat', 'lon', 'spd', 'dir' )\n",
    "# neste exemplo quando retorna, acaba acontecendo um erro de conversao em str e int , nao descobrir o pq, mas acontece\n",
    "# quando mando o nome dos parametros 'LAT', LON OU ALGO ASSIM\n",
    "# ================================================================================================================\n",
    "# ========= EXPLICAÇÃO DA FUNCAO \n",
    "# chame a função mandando um dataframe já aberto, logo apos dentro da função ele reabre o dataframe\n",
    "# pega as variaveis, direcao do vento, velocidade do vento, lat e lon \n",
    "# clacula o vento e retorna lat,lon, u_norm e v_norm\n",
    "\n",
    "# ================================================================================================================\n",
    "#==============================FUNCIONA EXCLUSIVAMENTE PARA OS ARQUIVOS DE CSV INPE==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f94dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "def reprojetando_imagens( arquivo_acht, caminho_acht, var, my_extent):\n",
    "    # CRIANDO PASTAS DE DADOS \n",
    "    #input = \"DADOS/GOES ACHT/\"; os.makedirs(input, exist_ok=True)\n",
    "    # output = caminho_acht + \"Output\"; os.makedirs(output, exist_ok=True)\n",
    "    output = caminho_acht; os.makedirs(output, exist_ok=True)\n",
    "\n",
    "    # PEGANDO A EXTENSAO DEFINIDA \n",
    "    extent = my_extent\n",
    "    file_name = arquivo_acht\n",
    "    #-----------------------------------------------------------------------------------------------------------\n",
    "    # Variable\n",
    "    var =  var\n",
    "\n",
    "    # Open the file\n",
    "    #img = gdal.Open(f'NETCDF:{input}/{file_name}:' + var)\n",
    "    img = gdal.Open(f'NETCDF:{file_name}:' + var)\n",
    "\n",
    "    # Data Quality Flag (DQF)\n",
    "    dqf = gdal.Open(f'NETCDF:{file_name}:DQF')\n",
    "\n",
    "    # Read the header metadata\n",
    "    metadata = img.GetMetadata()\n",
    "    scale = float(metadata.get(var + '#scale_factor'))\n",
    "    offset = float(metadata.get(var + '#add_offset'))\n",
    "    undef = float(metadata.get(var + '#_FillValue'))\n",
    "    dtime = metadata.get('NC_GLOBAL#time_coverage_start')\n",
    "    \n",
    "    # Load the data\n",
    "    ds = img.ReadAsArray(0, 0, img.RasterXSize, img.RasterYSize).astype(float)\n",
    "    ds_dqf = dqf.ReadAsArray(0, 0, dqf.RasterXSize, dqf.RasterYSize).astype(float)\n",
    "\n",
    "    # Apply the scale, offset and convert to celsius\n",
    "    ds = (ds * scale + offset)\n",
    "\n",
    "    # Apply NaN's where the quality flag is greater than 1\n",
    "    ds[ds_dqf > 1] = np.nan\n",
    "\n",
    "    # Reproject the file\n",
    "    nome_imagem = file_name.split('/')[-1]\n",
    "    filename_ds = f'{output}/{nome_imagem}_ret.nc'\n",
    "    reproject(filename_ds, img, ds, extent, undef) # salvando o arquivo no output \n",
    "    print('Pronto a reprojeçao do arquivo, salvo em \\n ', filename_ds)\n",
    "    return filename_ds\n",
    "#-----------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a649c1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ===================================REPROJETAR A IMAGEM DO PRODUTO GOES 16 L2 - ==============================\n",
    "# LINK ---> https://www.youtube.com/watch?v=ESlTKAGRgbY&t=1s  a partir das 4 horas de video\n",
    "# LINK - >  SCRIPT 14 E 15 Da pasta do curso do GNC 2021 \n",
    "# ================================================================================================================\n",
    "# Function to reproject the data\n",
    "def reproject(file_name, ncfile, array, extent, undef):\n",
    "\n",
    "    # Read the original file projection and configure the output projection\n",
    "    source_prj = osr.SpatialReference()\n",
    "    source_prj.ImportFromProj4(ncfile.GetProjectionRef())\n",
    "\n",
    "    target_prj = osr.SpatialReference()\n",
    "    target_prj.ImportFromProj4(\"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\")\n",
    "   \n",
    "    # Reproject the data\n",
    "    GeoT = ncfile.GetGeoTransform()\n",
    "    driver = gdal.GetDriverByName('MEM')\n",
    "    raw = driver.Create('raw', array.shape[0], array.shape[1], 1, gdal.GDT_Float32)\n",
    "    raw.SetGeoTransform(GeoT)\n",
    "    raw.GetRasterBand(1).WriteArray(array)\n",
    "\n",
    "    # Define the parameters of the output file  \n",
    "    kwargs = {'format': 'netCDF', \\\n",
    "            'srcSRS': source_prj, \\\n",
    "            'dstSRS': target_prj, \\\n",
    "            'outputBounds': (extent[0], extent[3], extent[2], extent[1]), \\\n",
    "            'outputBoundsSRS': target_prj, \\\n",
    "            'outputType': gdal.GDT_Float32, \\\n",
    "            'srcNodata': undef, \\\n",
    "            'dstNodata': 'nan', \\\n",
    "            'resampleAlg': gdal.GRA_NearestNeighbour}\n",
    "\n",
    "    # Write the reprojected file on disk\n",
    "    gdal.Warp(file_name, raw, **kwargs)\n",
    "\n",
    "# ================================================================================================================\n",
    "# explicação da função ainda nao fiz ..\n",
    "# ================================================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "689ac6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ========================================== PARA OBTER O VALOR NO PONTO ESPECIFICO ===========================\n",
    "##============= E RECORTAR AO REDOR DO PONTO =====================================\n",
    "#\n",
    "## ======================================================================================================\n",
    "#def criando_recorte(filename_ds, lon, lat):\n",
    "## Caminho para o arquivo NetCDF\n",
    "#    file_path = filename_ds\n",
    "#    \n",
    "#    # latitude_desejada = float(dados_inpe_100_200['lat'].values[1])   # Substitua pela latitude desejada\n",
    "#    # longitude_desejada = float(dados_inpe_100_200['lon'].values[1])  # Substitua pela longitude desejada\n",
    "#    latitude_desejada = float(lat)   # Substitua pela latitude desejada\n",
    "#    longitude_desejada = float(lon)  # Substitua pela longitude desejada\n",
    "#\n",
    "#    # Carregue o arquivo NetCDF usando xarray\n",
    "#    dataset = xr.open_dataset(file_path)\n",
    "#\n",
    "#    # Encontre os índices mais próximos para a latitude e longitude desejadas\n",
    "#    lon_index = abs(dataset['lon'] - longitude_desejada).argmin().item()\n",
    "#    lat_index = abs(dataset['lat'] - latitude_desejada).argmin().item()\n",
    "#    \n",
    "#\n",
    "#    # Extraia o ponto específico\n",
    "#    try:\n",
    "#        dados_ponto = dataset['Band1'][lon_index, lat_index].item()\n",
    "#        #dados_ponto = dataset['Band1'][longitude_desejada,latitude_desejada].item()\n",
    "#    except IndexError:\n",
    "#        #print(f\"Erro ao acessar os dados no ponto lon {lon_index} lat {lat_index}\")\n",
    "#        dataset.close()\n",
    "#        return None, None\n",
    "#\n",
    "##     dados_ponto = dataset['Band1'][lon_index, lat_index].item()\n",
    "#    #print(\"Valor na posição (lat={}, lon={}): {}\".format(latitude_desejada, longitude_desejada,dados_ponto))\n",
    "#        \n",
    "#     # Verifique as dimensões do arquivo\n",
    "#    max_lon_index = dataset.dims['lon'] - 1\n",
    "#    max_lat_index = dataset.dims['lat'] - 1\n",
    "#\n",
    "#    # Ajuste os índices para garantir que o recorte não ultrapasse as dimensões do arquivo\n",
    "#    lon_start = max(0, lon_index - 9)\n",
    "#    lon_end = min(max_lon_index, lon_index + 10)\n",
    "#    lat_start = max(0, lat_index - 9)\n",
    "#    lat_end = min(max_lat_index, lat_index + 10)\n",
    "#\n",
    "#     # Verifique se os índices estão dentro dos limites\n",
    "#    if lon_start > max_lon_index or lon_end >= dataset.sizes['lon'] or \\\n",
    "#            lat_start > max_lat_index or lat_end >= dataset.sizes['lat']:\n",
    "#            dataset.close()\n",
    "#            return None, None\n",
    "#    \n",
    "#        # Recorte a região 19x19 pixels ao redor do ponto desejado\n",
    "#    recorte = dataset['Band1'][lon_start:lon_end, lat_start:lat_end]\n",
    "#\n",
    "##     recorte = dataset['Band1'][lon_index - 9:lon_index + 10, \n",
    "##                                            lat_index - 9 : lat_index + 10 ]\n",
    "#\n",
    "#    #print(\"Valor para o ponto de latitude {} e longitude {}: {}\".format(latitude_desejada, longitude_desejada, dados_ponto))\n",
    "##     print('forma do recorte: ', recorte.shape)\n",
    "#\n",
    "#    # Feche o arquivo NetCDF\n",
    "#    dataset.close()\n",
    "#    return recorte, dados_ponto\n",
    "## fim\n",
    "#\n",
    "## ====================================================================================================== VERSAO 2 -========================\n",
    "\n",
    "def criando_recorte(filename_ds, lon, lat): \n",
    "# Caminho para o arquivo NetCDF\n",
    "    file_path = filename_ds\n",
    "    \n",
    "    latitude_desejada = float(lat)   # Substitua pela latitude desejada\n",
    "    longitude_desejada = float(lon)  # Substitua pela longitude desejada\n",
    "\n",
    "    # Carregue o arquivo NetCDF usando xarray\n",
    "    dataset = xr.open_dataset(file_path)\n",
    "\n",
    "    # Encontre os índices mais próximos para a latitude e longitude desejadas\n",
    "    lon_index = abs(dataset['lon'] - longitude_desejada).argmin().item()\n",
    "    lat_index = abs(dataset['lat'] - latitude_desejada).argmin().item()\n",
    "    \n",
    "    valor_pixel = dataset['Band1'][lon_index, lat_index].item()\n",
    "\n",
    " #     dados_ponto = dataset['Band1'][lon_index, lat_index].item()\n",
    "    #print(\"Valor na posição (lat={}, lon={}): {}\".format(latitude_desejada, longitude_desejada,dados_ponto))\n",
    "        \n",
    "     # Verifique as dimensões do arquivo\n",
    "    max_lon_index = dataset.dims['lon'] - 1\n",
    "    max_lat_index = dataset.dims['lat'] - 1\n",
    "\n",
    "    # Ajuste os índices para garantir que o recorte não ultrapasse as dimensões do arquivo\n",
    "    lon_start = max(0, lon_index - 9)\n",
    "    lon_end = min(max_lon_index, lon_index + 10)\n",
    "    lat_start = max(0, lat_index - 9)\n",
    "    lat_end = min(max_lat_index, lat_index + 10)\n",
    "\n",
    "     # Verifique se os índices estão dentro dos limites\n",
    "    if lon_start > max_lon_index or lon_end >= dataset.sizes['lon'] or \\\n",
    "            lat_start > max_lat_index or lat_end >= dataset.sizes['lat']:\n",
    "            dataset.close()\n",
    "            return None, None\n",
    "    \n",
    "        # Recorte a região 19x19 pixels ao redor do ponto desejado\n",
    "    recorte = dataset['Band1'][lon_start:lon_end, lat_start:lat_end]\n",
    "\n",
    "    # Feche o arquivo NetCDF\n",
    "    dataset.close()\n",
    "    return recorte, valor_pixel\n",
    "# fim\n",
    "# =================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7e4b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================ FUNCAO PARA ARRUMAR OS 9 MIN A MAIS DO ARQUIVO\n",
    "from datetime import timedelta\n",
    "\n",
    "def arruma_9(data):\n",
    "    delta = timedelta(minutes = 9)\n",
    "    data_arrumada =data -delta \n",
    "#     print(data_arrumada )\n",
    "    return data_arrumada\n",
    "\n",
    "\n",
    "# ======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e43bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOSTRANDO PIXEL A PIXEL PARA VERIFICAR O PIXEL CENTRAL E SALVANDO EM UM VETOR PARA CALCULAR AS MEDIAS \n",
    "# ======================================================================================================\n",
    "# MOSTRANDO PIXEL A PIXEL PARA VERIFICAR O PIXEL CENTRAL E SALVANDO EM UM VETOR PARA CALCULAR AS MEDIAS \n",
    "# ======================================================================================================\n",
    "\n",
    "def vetor_dados_recorte(recorte):\n",
    "    \n",
    "    vetor_aux = []\n",
    "    linha = recorte.shape[0] \n",
    "    coluna = recorte.shape[1]\n",
    "    if linha * coluna == 361:\n",
    "#         print(linha, coluna)\n",
    "        for i in range(linha):  # Itera sobre as linhas (latitude)\n",
    "            for j in range(coluna):  # Itera sobre as colunas (longitude)\n",
    "                valor_pixel = recorte[j,i ].values  # Acessa o valor do pixel\n",
    "                vetor_aux.append(valor_pixel)\n",
    "                # Faça o que quiser com o valor do pixel, por exemplo, imprimir\n",
    "                #print(\"Valor do pixel na posição ({}, {}): {}\".format(j, i, valor_pixel))\n",
    "        #print(\" tamanho do vetor \", len(vetor_aux))\n",
    "        #vetor_aux = float(vetor_aux)\n",
    "        return vetor_aux\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# ==========================================================================================================        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696d632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================== CRIANDO FUNCAO PARA CALCULAR  AS PORCENTAGENS ==================================\n",
    "#=====================================================================================\n",
    "#vetor_aux = vetor_dados_recorte(recorte)\n",
    "# ====== PEGANDO OS % MAIS FRIO E MAIS QUENTES \n",
    "# a variavel valor é quem recebe a porcentaem a ser calculada\n",
    "def porcentagens(vetor_aux, valor):\n",
    "    vet_ord = np.sort(vetor_aux)\n",
    "    vet_ord_inv = vet_ord[::-1]\n",
    "\n",
    "    n = int(valor * len(vet_ord))\n",
    "    vet_frio =  vet_ord[:n]\n",
    "    vet_quente = vet_ord_inv[:n]\n",
    "\n",
    "# =============================================================================================\n",
    "    quente = np.nanmean(vet_frio)\n",
    "    quente = quente.round(2)\n",
    "    frio =  np.nanmean(vet_quente)\n",
    "    frio = quente.round(2)\n",
    "    media_geral = np.nanmean(vet_ord)\n",
    "    media_geral = media_geral.round(2)\n",
    "    print(\" {} mais frios \\n  {} todos \" .format(quente, media_geral))\n",
    "    return quente,frio, media_geral\n",
    "\n",
    "# np.nanmean(vet_30_quente)\n",
    "\n",
    "\n",
    "# ======================================================================================================\n",
    "# EXPLICAÇÕES \n",
    "\n",
    "\n",
    "\n",
    "# ======================================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4d366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcao desvio padrao\n",
    "def calc_dev_padrao(vetor_aux):\n",
    "    vetor_aux = np.nanmean(vetor_aux)\n",
    "    desv = np.std(vetor_aux)\n",
    "    return desv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "586e0fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================FUNÇÃO PARA ARMAZENAR OS ARQUIVOS EM UM CSV =============================\n",
    "# ======================================================================================================\n",
    "# dados = [lat, lon, valor_pixel_no_ponto, quente,frio, media_todos,\n",
    "#          float(dados_inpe_100_200['temp'].values[4]),\n",
    "#          float(dados_inpe_100_200['press'].values[4])]\n",
    "# colunas = [ 'lat', 'lon', 'temp_na_lat_lon_exata', 'media_quente',\n",
    "#            'media_frio', 'media_19x19', 'Temp_AMV_INPE', 'PRESS_AMV_INPE' ] \n",
    "\n",
    "# def armazena_dados( caminho_arquivo, lista_arquivos, dados, colunas):\n",
    "#     output = caminho_arquivo + \"Output_txt\"; os.makedirs(output, exist_ok=True)\n",
    "#     file_name = lista_arquivos\n",
    "#     nome_imagem = file_name.split('/')[-1]\n",
    "#     nome_arquivo = f'{output}/{nome_imagem}_ret.csv'\n",
    "    \n",
    "#     if os.path.isfile(nome_arquivo):\n",
    "#         # Se o arquivo existe, abra-o e salve os dados\n",
    "#         df = pd.read_csv(nome_arquivo)\n",
    "#         novo_dados = pd.DataFrame([dados], columns=colunas )\n",
    "#         df = df.append(novo_dados, ignore_index=True)\n",
    "#         df.to_csv(nome_arquivo, index=False ) # , sep = ','\n",
    "#         print(f'Dados adicionados ao arquivo existente {nome_imagem}')\n",
    "#     else:\n",
    "#         # Se o arquivo não existe, crie um novo arquivo com as colunas e salve os dados\n",
    "#         df = pd.DataFrame([dados], columns=colunas)\n",
    "#         df.to_csv(nome_arquivo, index=False, sep = ',')\n",
    "#         print(f'Novo arquivo criado e dados armazenados.{nome_imagem}')\n",
    "\n",
    "# # armazena_dados( caminho_acht, arquivo_acht[1], dados, colunas)\n",
    "\n",
    "# ==========================================================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def armazena_dados( caminho_arquivo, lista_arquivos, dados, colunas):\n",
    "    output = caminho_arquivo + \"Output_txt\"; os.makedirs(output, exist_ok=True)\n",
    "    file_name = lista_arquivos\n",
    "    nome_imagem = file_name.split('/')[-1]\n",
    "    nome_arquivo = f'{output}/{nome_imagem}_ret.csv'\n",
    "    \n",
    "    if os.path.isfile(nome_arquivo):\n",
    "        # Se o arquivo existe, abra-o e salve os dados\n",
    "        df = pd.read_csv(nome_arquivo)\n",
    "        novo_dados = pd.DataFrame([dados], columns=colunas )\n",
    "#         df = df.append(novo_dados, ignore_index=True)\n",
    "        \n",
    "        df = pd.concat([df, novo_dados], ignore_index=True)\n",
    "\n",
    "#         df = df.append(pd.DataFrame([dados], columns=colunas), ignore_index=True)\n",
    "        df.to_csv(nome_arquivo, index=False ) # , sep = ','\n",
    "        print(f'Dados adicionados ao arquivo existente {nome_imagem}')\n",
    "    else:\n",
    "        # Se o arquivo não existe, crie um novo arquivo com as colunas e salve os dados\n",
    "        df = pd.DataFrame([dados], columns=colunas)\n",
    "        df.to_csv(nome_arquivo, index=False, sep = ',')\n",
    "        print(f'Novo arquivo criado e dados armazenados.{nome_imagem}')\n",
    "\n",
    "# armazena_dados( caminho_acht, arquivo_acht[1], dados, colunas)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================================================================\n",
    "# EXPLICAÇOES\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d09f29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================================\n",
    "# ====================================================================================\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "def converte_dia_juliano(dia_juliano, ano):\n",
    "    dia_juliano= int(dia_juliano)\n",
    "    ano = int(ano)\n",
    "    \n",
    "    # Calcula a data a partir do dia juliano e ano\n",
    "    data_inicio_ano = dt.datetime(ano, 1, 1)\n",
    "    data_dia_juliano = data_inicio_ano + dt.timedelta(days = dia_juliano - 1)\n",
    "\n",
    "#     return data_dia_juliano.strftime('%Y-%m-%d')\n",
    "    return data_dia_juliano\n",
    "# ====================================================================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ===================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cce631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================================\n",
    "# FUNÃO PARA CONVERTAR UMA PARTE DO ARQUIVO TEXTO DO NC PARA HORA\n",
    "# FUNCAO QUEBRA GALHO\n",
    "\n",
    "def convertendo_em_hora_mes_dia(arquivo):\n",
    "    dados = arquivo\n",
    "    separando = dados.split('/')[-1]\n",
    "    sep_data_hora = separando.split('_')[-3]\n",
    "    ano = sep_data_hora[1:5]\n",
    "    dj = sep_data_hora[5:8]\n",
    "    hora = sep_data_hora[8:12]\n",
    "    data_arquivo = converte_dia_juliano(dj, ano)\n",
    "    data_e_hora = data_arquivo.strftime('%Y%m%d') + hora\n",
    "    data_e_hora  = dt.datetime.strptime(data_e_hora, '%Y%m%d%H%M')\n",
    "    return data_e_hora\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "def converte_dia_juliano(dia_juliano, ano):\n",
    "    dia_juliano= int(dia_juliano)\n",
    "    ano = int(ano)\n",
    "    \n",
    "    # Calcula a data a partir do dia juliano e ano\n",
    "    data_inicio_ano = dt.datetime(ano, 1, 1)\n",
    "    data_dia_juliano = data_inicio_ano + dt.timedelta(days = dia_juliano - 1)\n",
    "\n",
    "#     return data_dia_juliano.strftime('%Y-%m-%d')\n",
    "    return data_dia_juliano\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f4633a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==== =============================== PLOTANDO RECORTE ========================================================\n",
    "\n",
    "def plotando_recorte(lat, lon, recorte):\n",
    "    # Coordenadas do ponto central do recorte\n",
    "    latitude_central = float(lat)  # Substitua pela latitude central do recorte\n",
    "    longitude_central = float(lon)  # Substitua pela longitude central do recorte\n",
    "    tam_grade = 10\n",
    "    # Criando arrays de latitude e longitude para o recorte\n",
    "    latitudes = np.linspace(latitude_central - int(tam_grade), \n",
    "                            latitude_central + int(tam_grade), num=recorte.shape[0])\n",
    "    longitudes = np.linspace(longitude_central - int(tam_grade), \n",
    "                            longitude_central + int(tam_grade), num=recorte.shape[1])\n",
    "\n",
    "    data = plt.imshow(recorte.values, cmap='Greys_r',\n",
    "              extent=[longitudes[0], longitudes[-1], latitudes[-1], latitudes[0]])  # Plotando a imagem diretamente\n",
    "\n",
    "    # #=============\n",
    "    # long,lati, u_norm, v_norm = fpl.calcula_vento(dados_inpe_100_200) #,'lat', 'lon', 'spd', 'dir' )\n",
    "\n",
    "    # plt.quiver(long, lati, v_norm , u_norm,   scale= 60,  \n",
    "    #                     pivot = \"tip\", alpha=1,\n",
    "    #                     #width = 0.005  ,\n",
    "    #                     color =  'pink'  #'lightblue' \n",
    "    # #             \n",
    "    #                       )\n",
    "\n",
    "    plt.plot(lon, lat, 'ro', markersize=3)\n",
    "\n",
    "\n",
    "    #plt.scatter(recorte.shape,recorte.shape,recorte.values)\n",
    "    plt.colorbar(data )  # Adiciona uma barra de cores para a escala\n",
    "    plt.title('Recorte 19x19 pixels', loc = 'left')\n",
    "    plt.title(str(latitude_central) + str(longitude_central) ,\n",
    "              loc = 'right', fontsize = 10)\n",
    "\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.show()\n",
    "    \n",
    "# ============\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885acb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================GERANDO GIF =============================================================\n",
    "# ==========================GERANDO GIF=======================================================\n",
    "# ==================================================================================================\n",
    "# import shutil\n",
    "# import imageio\n",
    "# import matplotlib.pyplot as plt\n",
    "# from IPython.display import display, Image\n",
    "\n",
    "\n",
    "# def gerando_gif(caminho_imagem, saida, nome_arquivo):\n",
    "    # \n",
    "    # imagens = fpl.retorna_lista(caminho_imagem)\n",
    "# \n",
    "    ## Crie o GIF\n",
    "    # fps = 5\n",
    "    # with imageio.get_writer('animacao.gif', mode='I', duration = 1.0/ fps) as writer:\n",
    "        # for imagem in imagens:\n",
    "            # imagem = imageio.imread(imagem)\n",
    "            ##writer.append_data(imagem)\n",
    "#     with open('animacao.gif', 'rb') as file:\n",
    "#         display(Image(file.read()))\n",
    "\n",
    "# Para salvar o GIF em um local específico\n",
    "\n",
    "#    shutil.move('animacao.gif', f'{saida}{nome_arquivo}.gif')\n",
    "\n",
    "# =====================================================================\n",
    "# ====================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718a518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------criando funcao de definir altura ---------- NUNCA USEI =======\n",
    "def calcular_altura(pressao, temperatura):\n",
    "    #DEFININDO CONSTANTES \n",
    "    R = 8.314 #J/(mol·K)),\n",
    "    P0 = 1000 #PRESSAO INICIAL\n",
    "    P = pressao\n",
    "    T = temperatura  # kelvin\n",
    "    g = 9.81 #m/s2\n",
    "  \n",
    "    h = (R*T/g) * np.log(P0/P)\n",
    "    #h= pd.DataFrame(h)\n",
    "    return h\n",
    "# ----------------------------------------------------------------------------\n",
    "# -- DESCRICAO----\n",
    "#  chame a funcao e  mande uma pressao em hpa e temperatura em kelvin\n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b366924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ================================== FUNCAO REMAP PARA OS PRODUTOS DO GOES L2   =====================================\n",
    "# # LINK DROPBOX ---> https://www.dropbox.com/s/r5q6e05i1sgw5br/remap.py?dl=0\n",
    "# # LINK DROPBOX 2 ---> https://www.dropbox.com/s/2zylbwfjfkx9a7i/GNC-A%20Blog%20-%20GOES-R-Level-2-Products.py?dl=0\n",
    "# # LINK GNC EXPLICANDO --> https://geonetcast.wordpress.com/2018/06/28/goes-r-level-2-products-a-python-script/\n",
    "# # \n",
    "# # =========================================================================\n",
    "# #from netCDF4 import Dataset\n",
    "# # import numpy as np\n",
    "# # from osgeo import osr\n",
    "# # from osgeo import gdal\n",
    "# # import time as t\n",
    "\n",
    "# # Define KM_PER_DEGREE\n",
    "# KM_PER_DEGREE = 111.32\n",
    "\n",
    "# # GOES-16 Spatial Reference System\n",
    "# sourcePrj = osr.SpatialReference()\n",
    "# #sourcePrj.ImportFromProj4('+proj=geos +h=35786023.0 +a=6378137.0 +b=6356752.31414 +f=0.00335281068119356027489803406172 +lat_0=0.0 +lon_0=-75 +sweep=x +no_defs')\n",
    "# sourcePrj.ImportFromProj4('+proj=geos +h=35786000 +a=6378140 +b=6356750 +lon_0=-75 +sweep=x')\n",
    "\n",
    "# # Lat/lon WSG84 Spatial Reference System\n",
    "# targetPrj = osr.SpatialReference()\n",
    "# #targetPrj.ImportFromProj4('+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs')\n",
    "# targetPrj.ImportFromProj4('+proj=latlong +datum=WGS84')\n",
    "\n",
    "# def exportImage(image,path):\n",
    "#     driver = gdal.GetDriverByName('netCDF')\n",
    "#     return driver.CreateCopy(path,image,0)\n",
    "\n",
    "# def getGeoT(extent, nlines, ncols):\n",
    "#     # Compute resolution based on data dimension\n",
    "#     resx = (extent[2] - extent[0]) / ncols\n",
    "#     resy = (extent[3] - extent[1]) / nlines\n",
    "#     return [extent[0], resx, 0, extent[3] , 0, -resy]\n",
    "\n",
    "# def getScaleOffset(path, variable):\n",
    "#     nc = Dataset(path, mode='r')\n",
    "    \n",
    "#     if (variable == \"BCM\") or (variable == \"Phase\") or (variable == \"Smoke\") or (variable == \"Dust\") or (variable == \"Mask\") or (variable == \"Power\"): \n",
    "#         scale = 1\n",
    "#         offset = 0     \n",
    "#     else:\n",
    "#         scale = nc.variables[variable].scale_factor\n",
    "#         offset = nc.variables[variable].add_offset\n",
    "#     #scale = 0\n",
    "#     #offset = 0\n",
    "#     nc.close()\n",
    "#     return scale, offset\n",
    "    \n",
    "# def remap(path, variable, extent, resolution, x1, y1, x2, y2):\n",
    "    \n",
    "#     scale = 1\n",
    "#     offset = 0\n",
    "    \n",
    "#     # GOES-16 Extent (satellite projection) [llx, lly, urx, ury]\n",
    "#     GOES16_EXTENT = [x1, y1, x2, y2]\n",
    "    \n",
    "#     # Setup NetCDF driver\n",
    "#     gdal.SetConfigOption('GDAL_NETCDF_BOTTOMUP', 'NO')\n",
    "        \n",
    "#     if not (variable == \"DQF\"):              \n",
    "#         # Read scale/offset from file\n",
    "#         scale, offset = getScaleOffset(path, variable) \n",
    "#         #print(scale)\n",
    "#         #print(offset)\n",
    "      \n",
    "#     connectionInfo = 'HDF5:\\\"' + path + '\\\"://' + variable\n",
    "#     #print(connectionInfo)\n",
    "#     #connectionInfo = 'HDF5:\"E:\\VLAB\\Python\\GOES-16 Samples - L2\\OR_ABI-L2-CMIPF-M3C13_G16_s20180571300407_e20180571311185_c20180571311263.nc\"://CMI'\n",
    "#     raw = gdal.Open(connectionInfo)\n",
    "       \n",
    "#     #print(\"Connection Info:\")\n",
    "#     #print(connectionInfo)            \n",
    "    \n",
    "#     # Setup projection and geo-transformation\n",
    "#     raw.SetProjection(sourcePrj.ExportToWkt())\n",
    "#     #raw.SetGeoTransform(getGeoT(GOES16_EXTENT, raw.RasterYSize, raw.RasterXSize))\n",
    "#     raw.SetGeoTransform(getGeoT(GOES16_EXTENT, raw.RasterYSize, raw.RasterXSize))  \n",
    "  \n",
    "#     #print (KM_PER_DEGREE)\n",
    "#     # Compute grid dimension\n",
    "#     sizex = int(((extent[2] - extent[0]) * KM_PER_DEGREE) / resolution)\n",
    "#     sizey = int(((extent[3] - extent[1]) * KM_PER_DEGREE) / resolution)\n",
    "    \n",
    "#     # Get memory driver\n",
    "#     memDriver = gdal.GetDriverByName('MEM')\n",
    "   \n",
    "#     # Create grid\n",
    "#     grid = memDriver.Create('grid', sizex, sizey, 1, gdal.GDT_Float32)\n",
    "        \n",
    "#     # Setup projection and geo-transformation\n",
    "#     grid.SetProjection(targetPrj.ExportToWkt())\n",
    "#     grid.SetGeoTransform(getGeoT(extent, grid.RasterYSize, grid.RasterXSize))\n",
    "\n",
    "#     # Perform the projection/resampling \n",
    "\n",
    "#     print ('Remapeando... ', path)\n",
    "        \n",
    "#     start = t.time()\n",
    "    \n",
    "#     gdal.ReprojectImage(raw, grid, sourcePrj.ExportToWkt(), targetPrj.ExportToWkt(), \n",
    "#                         gdal.GRA_NearestNeighbour, options=['NUM_THREADS=ALL_CPUS']) \n",
    "    \n",
    "#     print ('Pronto!! Tempo:', t.time() - start, 'segundos')\n",
    "    \n",
    "#     # Read grid data\n",
    "#     array = grid.ReadAsArray()\n",
    "    \n",
    "#     # Mask fill values (i.e. invalid values)\n",
    "#     np.ma.masked_where(array, array == -1, False)\n",
    "    \n",
    "#     array = array.astype(np.uint16)  \n",
    "       \n",
    "#     # Apply scale and offset\n",
    "#     array = array * scale + offset\n",
    "#     #np.ma.masked_where(array, array == 100, False)\n",
    "#     #print(array)\n",
    "    \n",
    "#     #grid.GetRasterBand(1).SetNoDataValue(-1)\n",
    "#     grid.GetRasterBand(1).WriteArray(array)\n",
    "\n",
    "#     # fechando arquivo\n",
    "#     raw = None\n",
    "        \n",
    "#     return grid\n",
    "\n",
    "\n",
    "# # ========================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
